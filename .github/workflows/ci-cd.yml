# CI/CD Pipeline with AWS Secrets Manager Integration
#
# Required GitHub Secrets:
#   - AWS_ROLE_ARN: ARN of the IAM role for OIDC authentication
#   - AWS_REGION: AWS region (e.g., us-east-1)
#   - SECRET_MANAGER_NAME: Name of the secret in AWS Secrets Manager
#   - EKS_CLUSTER_NAME: Name of the EKS cluster
#
# AWS Secrets Manager Setup:
#   The secret should be stored as JSON with the following structure:
#   {
#     "API_KEY": "your-actual-api-key-value"
#   }
#   Alternatively, store as plain text and modify line 204 accordingly.
#
# IAM Role Permissions Required:
#   - secretsmanager:GetSecretValue
#   - eks:DescribeCluster
#   - eks:ListClusters
#
name: CI/CD Pipeline

on:
  push:
    branches:
      - main
      - develop
    paths:
      - 'src/**'
      - 'kube/**'
      - '.github/workflows/**'
  pull_request:
    branches:
      - main
      - develop
    paths:
      - 'src/**'
      - 'kube/**'
      - '.github/workflows/**'

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}

jobs:
  build-and-test:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write
    outputs:
      image-tag: ${{ steps.meta.outputs.tags }}
      image-digest: ${{ steps.build.outputs.digest }}
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          sparse-checkout: |
            src
            kube
          sparse-checkout-cone-mode: false

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
        with:
          driver-opts: |
            network=host
            image=moby/buildkit:buildx-stable-1

      - name: Log in to Container Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Extract metadata for Docker
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}
          tags: |
            type=ref,event=branch
            type=ref,event=pr
            type=sha,prefix={{branch}}-
            type=raw,value=latest,enable={{is_default_branch}}

      - name: Build and push Docker image
        id: build
        uses: docker/build-push-action@v5
        with:
          context: ./src
          file: ./src/Dockerfile
          push: true
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: |
            type=registry,ref=${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:buildcache
            type=gha
          cache-to: |
            type=registry,ref=${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:buildcache,mode=max
            type=gha,mode=max
          platforms: linux/amd64
          provenance: false
          sbom: false

  test:
    needs: build-and-test
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: read
    
    steps:
      - name: Log in to Container Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Pull and test image
        run: |
          IMAGE_TAG=$(echo "${{ needs.build-and-test.outputs.image-tag }}" | head -n 1)
          echo "Testing image: $IMAGE_TAG"
          
          docker pull "$IMAGE_TAG"
          docker run -d --name test-container -p 3000:3000 \
            -e PORT=3000 \
            "$IMAGE_TAG"
          
          # Wait for container to be ready
          echo "Waiting for container to start..."
          sleep 5

      - name: Health check test
        run: |
          max_attempts=15
          attempt=0
          
          while [ $attempt -lt $max_attempts ]; do
            if curl -f http://localhost:3000/health; then
              echo "✓ Health check passed!"
              break
            fi
            
            attempt=$((attempt + 1))
            echo "Attempt $attempt/$max_attempts failed, retrying..."
            sleep 2
          done
          
          if [ $attempt -eq $max_attempts ]; then
            echo "✗ Health check failed after $max_attempts attempts"
            docker logs test-container
            exit 1
          fi

      - name: API endpoint test
        run: |
          response=$(curl -s http://localhost:3000/)
          echo "Response: $response"
          
          if echo "$response" | grep -q "Hello from Node.js app"; then
            echo "✓ API test passed!"
          else
            echo "✗ API test failed!"
            docker logs test-container
            exit 1
          fi

      - name: Cleanup
        if: always()
        run: |
          docker stop test-container || true
          docker rm test-container || true
          docker system prune -f || true

  deploy:
    needs: [build-and-test, test]
    runs-on: ubuntu-latest
    if: github.event_name != 'pull_request' && github.ref == 'refs/heads/main'
    permissions:
      contents: read
      packages: read
      id-token: write
    concurrency:
      group: deploy-${{ github.ref }}
      cancel-in-progress: false
    environment:
      name: production

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          sparse-checkout: |
            kube/helm
          sparse-checkout-cone-mode: false

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: ${{ secrets.AWS_REGION }}

      - name: Fetch API_KEY from AWS Secrets Manager
        id: fetch-secret
        run: |
          echo "Fetching API_KEY from AWS Secrets Manager..."
          
          SECRET_NAME="${{ secrets.SECRET_MANAGER_NAME }}"
          AWS_REGION="${{ secrets.AWS_REGION }}"
          
          # Fetch the secret from AWS Secrets Manager
          SECRET_VALUE=$(aws secretsmanager get-secret-value \
            --secret-id "$SECRET_NAME" \
            --region "$AWS_REGION" \
            --query SecretString \
            --output text)
          
          # Extract API_KEY from JSON (if secret is stored as JSON)
          # If secret is plain text, use: API_KEY="$SECRET_VALUE"
          API_KEY=$(echo "$SECRET_VALUE" | jq -r '.API_KEY')
          
          # Verify API_KEY was retrieved
          if [ -z "$API_KEY" ] || [ "$API_KEY" = "null" ]; then
            echo "ERROR: Failed to retrieve API_KEY from Secrets Manager"
            exit 1
          fi
          
          echo "✓ Successfully retrieved API_KEY from Secrets Manager"
          
          # Mask the secret in logs
          echo "::add-mask::$API_KEY"
          
          # Export to environment for next steps
          echo "API_KEY=$API_KEY" >> $GITHUB_ENV

      - name: Set up kubectl
        uses: azure/setup-kubectl@v3

      - name: Set up Helm
        uses: azure/setup-helm@v3
        with:
          version: 'v3.13.0'

      - name: Configure kubectl context
        run: |
          # Configure your Kubernetes cluster access here
          aws eks update-kubeconfig \
            --name ${{ secrets.EKS_CLUSTER_NAME }} \
            --region ${{ secrets.AWS_REGION }}

      - name: Deploy with Helm (atomic operation)
        timeout-minutes: 10
        run: |
          cd kube/helm
          
          IMAGE_TAG=$(echo "${{ needs.build-and-test.outputs.image-tag }}" | head -n 1)
          
          # Verify API_KEY is available
          if [ -z "$API_KEY" ]; then
            echo "ERROR: API_KEY is not available"
            exit 1
          fi
          
          echo "Deploying application with Helm..."
          
          helm upgrade --install nodejs-simple-app . \
            --namespace default \
            --create-namespace \
            --atomic \
            --cleanup-on-fail \
            --wait \
            --timeout 8m \
            --set image.repository=${{ env.REGISTRY }}/${{ env.IMAGE_NAME }} \
            --set image.tag=${{ github.sha }} \
            --set-string secret.apiKey.value="$API_KEY"

      - name: Verify deployment
        timeout-minutes: 5
        run: |
          kubectl rollout status deployment/nodejs-simple-app -n default --timeout=3m
          
          # Wait for pods to be ready
          kubectl wait --for=condition=ready pod \
            -l app.kubernetes.io/name=nodejs-simple-app \
            -n default \
            --timeout=3m
          
          echo "✓ Deployment successful!"

      - name: Clean up on failure
        if: failure()
        run: |
          echo "✗ Deployment failed, rolling back..."
          helm rollback nodejs-simple-app -n default || true

